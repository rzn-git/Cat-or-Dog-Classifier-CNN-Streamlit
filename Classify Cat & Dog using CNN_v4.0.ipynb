{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 123] The filename, directory name, or volume label syntax is incorrect: 'https://github.com/rzn-git/ML_Projects/tree/main/Classify%20Cat%20%26%20Dog%20using%20CNN/CNN_dataset/training_set'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m\n\u001b[0;32m     11\u001b[0m train_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m,\n\u001b[0;32m     12\u001b[0m                                    rotation_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     13\u001b[0m                                    width_shift_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m                                    zoom_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m     17\u001b[0m                                    horizontal_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     19\u001b[0m test_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(train_dir,\n\u001b[0;32m     22\u001b[0m                                                     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m150\u001b[39m),\n\u001b[0;32m     23\u001b[0m                                                     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     24\u001b[0m                                                     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m test_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(test_dir,\n\u001b[0;32m     27\u001b[0m                                                 target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m150\u001b[39m),\n\u001b[0;32m     28\u001b[0m                                                 batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     29\u001b[0m                                                 class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Building the CNN model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1138\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1122\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1136\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1137\u001b[0m ):\n\u001b[1;32m-> 1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DirectoryIterator(\n\u001b[0;32m   1139\u001b[0m         directory,\n\u001b[0;32m   1140\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1141\u001b[0m         target_size\u001b[38;5;241m=\u001b[39mtarget_size,\n\u001b[0;32m   1142\u001b[0m         color_mode\u001b[38;5;241m=\u001b[39mcolor_mode,\n\u001b[0;32m   1143\u001b[0m         keep_aspect_ratio\u001b[38;5;241m=\u001b[39mkeep_aspect_ratio,\n\u001b[0;32m   1144\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[0;32m   1145\u001b[0m         class_mode\u001b[38;5;241m=\u001b[39mclass_mode,\n\u001b[0;32m   1146\u001b[0m         data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format,\n\u001b[0;32m   1147\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1148\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m   1149\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m   1150\u001b[0m         save_to_dir\u001b[38;5;241m=\u001b[39msave_to_dir,\n\u001b[0;32m   1151\u001b[0m         save_prefix\u001b[38;5;241m=\u001b[39msave_prefix,\n\u001b[0;32m   1152\u001b[0m         save_format\u001b[38;5;241m=\u001b[39msave_format,\n\u001b[0;32m   1153\u001b[0m         follow_links\u001b[38;5;241m=\u001b[39mfollow_links,\n\u001b[0;32m   1154\u001b[0m         subset\u001b[38;5;241m=\u001b[39msubset,\n\u001b[0;32m   1155\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[0;32m   1156\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   1157\u001b[0m     )\n",
      "File \u001b[1;32mc:\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:453\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m    452\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(directory)):\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    455\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 123] The filename, directory name, or volume label syntax is incorrect: 'https://github.com/rzn-git/ML_Projects/tree/main/Classify%20Cat%20%26%20Dog%20using%20CNN/CNN_dataset/training_set'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Set up paths to your dataset\n",
    "train_dir = 'CNN_dataset/training_set'\n",
    "test_dir = 'CNN_dataset/test_set'\n",
    "\n",
    "# Image data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(150, 150),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                target_size=(150, 150),\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='binary')\n",
    "\n",
    "# Building the CNN model\n",
    "cnn = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "cnn.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "trained_cnn = cnn.fit(train_generator,\n",
    "                    epochs=25,\n",
    "                    validation_data=test_generator)\n",
    "\n",
    "# Save the model after training\n",
    "cnn.save('CNN_model/cnn_cat_or_dog_v5.0.keras')\n",
    "\n",
    "# Evaluating the model\n",
    "loss, accuracy = cnn.evaluate(test_generator)\n",
    "print(f'Validation Loss: {loss}')\n",
    "print(f'Validation Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
      "Cat. \n",
      "Confidence: 94 %\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "cnn = tf.keras.models.load_model('CNN_model/cnn_cat_or_dog_v4.0.keras')\n",
    "\n",
    "# Load and preprocess the image\n",
    "test_image = 'CNN_dataset/single_prediction/cat_or_dog_7.jpg'\n",
    "test_image = image.load_img(test_image, target_size=(150, 150))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)  # Add batch dimension\n",
    "test_image /= 255.0  # Normalize the image to the same scale as training data\n",
    "\n",
    "# Make a prediction\n",
    "prediction = cnn.predict(test_image)\n",
    "\n",
    "# Interpret the result\n",
    "if prediction[0] > 0.5:\n",
    "    print(f'Dog. \\nConfidence: {prediction[0][0]*100:.0f} %')\n",
    "else:\n",
    "    print(f'Cat. \\nConfidence: {(1 - prediction[0][0])* 100:.0f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('CNN_model/cnn_cat_or_dog_v4.0.keras')\n",
    "\n",
    "# Function to preprocess image\n",
    "def preprocess_image(img):\n",
    "    img = img.resize((150, 150))  # Resize image to match the model's input size\n",
    "    img_array = image.img_to_array(img)  # Convert the image to an array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array /= 255.0  # Normalize the image to the same scale as training data\n",
    "    return img_array\n",
    "\n",
    "# Streamlit app\n",
    "st.title(\"ðŸ¾ Cat or Dog Classifier using CNN\")\n",
    "\n",
    "st.write(\"Upload an image to classify ðŸ± or ðŸ¶. image format has to be jpg, jpeg or png\")\n",
    "\n",
    "# Image upload\n",
    "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    # Open and display the uploaded image\n",
    "    image_file = Image.open(uploaded_file)\n",
    "    st.image(image_file, caption=\"Uploaded Image\", use_column_width=True)\n",
    "\n",
    "    # Preprocess the uploaded image\n",
    "    img_array = preprocess_image(image_file)\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = model.predict(img_array)\n",
    "\n",
    "    # Interpret the result and display it\n",
    "    if prediction[0] > 0.5:\n",
    "        st.write(f\"**Prediction:** Dog\")\n",
    "        st.write(f\"**Confidence:** {prediction[0][0]*100:.2f}%\")\n",
    "    else:\n",
    "        st.write(f\"**Prediction:** Cat\")\n",
    "        st.write(f\"**Confidence:** {(1 - prediction[0][0])*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
